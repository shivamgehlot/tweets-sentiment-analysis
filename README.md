# ğŸ§  Sentiment Analysis Web App

**TF-IDF | LSTM | BERT (Fine-Tuned)**

An end-to-end **Sentiment Analysis system** that compares three different NLP approaches â€” **Traditional ML**, **Deep Learning**, and **Transformer-based models** â€” deployed using **Streamlit**.

---

## ğŸš€ Live Demo

ğŸ”— **

---

## ğŸ“Œ Project Overview

This project performs **binary sentiment classification (Positive / Negative)** on text data using:

1. **TF-IDF + Logistic Regression**
2. **LSTM Neural Network**
3. **Fine-tuned BERT (bert-base-uncased)**

The goal is to **compare accuracy, performance, and inference behavior** across different NLP paradigms.

---

## ğŸ—ï¸ Architecture

```
User Input
   â”‚
   â”œâ”€â”€ TF-IDF + Logistic Regression
   â”œâ”€â”€ LSTM (Keras)
   â””â”€â”€ BERT (Transformers)
        â”‚
        â–¼
   Sentiment Prediction + Confidence
```

---

## ğŸ§ª Models Used

### 1ï¸âƒ£ TF-IDF + Logistic Regression

* Feature extraction using **TF-IDF**
* Classifier: **Logistic Regression**
* Fast inference, lightweight

### 2ï¸âƒ£ LSTM (Deep Learning)

* Tokenization + padding (`max_len = 360`)
* Embedding + LSTM layers
* Better contextual understanding than TF-IDF

### 3ï¸âƒ£ BERT (Transformer)

* **bert-base-uncased**
* Fine-tuned using Hugging Face `Trainer`
* Highest accuracy, context-aware

---

## ğŸ“Š Training Results (Example)

| Model  | Validation Accuracy |
| ------ | ------------------- |
| TF-IDF | ~83%                |
| LSTM   | ~84%                |
| BERT   | ~86%                |

---

## ğŸ–¥ï¸ Web Application (Streamlit)

Features:

* Single text input
* Real-time predictions from **all three models**
* Confidence score display
* Clean UI for comparison

---

## ğŸ“ Project Structure

```
tweets-sentiment-analysis/
â”‚
â”œâ”€â”€ app.py                  # Streamlit app
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ preprocess.py       # Text cleaning
â”‚   â””â”€â”€ predict.py          # Model inference
â”‚
â”œâ”€â”€ notebook/               # Training notebooks
â”œâ”€â”€ models/                 # (ignored in GitHub)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## âš ï¸ Important Note About Models

> **Trained models are NOT included in this repository**

Reason:

* Large file sizes
* GitHub limitations
* Best practices

### Models are loaded from:

* Local storage (development)
* Hugging Face Hub (deployment)

---

## ğŸ› ï¸ Installation & Setup

### 1ï¸âƒ£ Clone repository

```bash
git clone https://github.com/shivamgehlot/tweets-sentiment-analysis.git
cd tweets-sentiment-analysis
```

### 2ï¸âƒ£ Create virtual environment

```bash
python -m venv venv
venv\Scripts\activate
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Run Streamlit app

```bash
streamlit run app.py
```

---

## ğŸ“¦ Dependencies

* Python 3.9+
* streamlit
* scikit-learn
* tensorflow
* torch
* transformers
* safetensors
* joblib
* numpy
* pandas
* huggingface_hub

---

## ğŸ¯ Key Learnings

* Difference between traditional ML, DL, and transformer models
* Model deployment considerations
* Managing large ML artifacts
* Streamlit deployment workflow
* Hugging Face Transformers usage

---

## ğŸ§‘â€ğŸ’» Author

**Shivam Gehlot**
Software Engineering | Machine Learning | NLP

ğŸ”— GitHub: [https://github.com/shivamgehlot](https://github.com/shivamgehlot)

---

## â­ Future Improvements

* Optimize BERT inference
* Add multilingual support

---

## ğŸ“œ License

This project is for **educational and portfolio purposes**.


